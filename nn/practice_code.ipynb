{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tsensor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nn = [1, 3, 4, 2, 1]\n",
    "inputs = np.random.randint(10, 100, 10).reshape(10, 1)\n",
    "tagets = [n + np.random.randint(-5, 5) for n in inputs]\n",
    "lr = 1e-5\n",
    "\n",
    "# instantiation ransom weights and biases\n",
    "np.random.seed(42)\n",
    "layers = []\n",
    "for i in range(1, len(nn)):\n",
    "    layers.append([np.random.rand(nn[i - 1], nn[i]) / 5 - 0.1, np.ones((1, nn[i]))])\n",
    "\n",
    "# forward pass\n",
    "l1_output = np.maximum(0, inputs @ layers[0][0] + layers[0][1])  # hidden layer 1 output\n",
    "l2_output = np.maximum(\n",
    "    0, l1_output @ layers[1][0] + layers[1][1]\n",
    ")  # hidden layer 2 output\n",
    "l3_output = np.maximum(\n",
    "    0, l2_output @ layers[2][0] + layers[2][1]\n",
    ")  # hidden layer 3 output\n",
    "output = l3_output @ layers[3][0] + layers[3][1]  # output layers without relu\n",
    "\n",
    "# back propagation and weight and bias updates\n",
    "# from output to layer 4\n",
    "output_gradient = output\n",
    "l4_w_gradient = l3_output.T @ output_gradient\n",
    "l4_b_gradient = np.mean(output_gradient, axis=0)\n",
    "layers[3][0] -= lr * l4_w_gradient\n",
    "layers[3][1] -= lr * l4_b_gradient\n",
    "\n",
    "# from layer4 to layer3\n",
    "l3_gradient = output_gradient @ layers[3][0].T * np.heaviside(l3_output, 0)\n",
    "l3_w_gradient = l2_output.T @ l3_gradient\n",
    "l3_b_gradient = np.mean(l3_gradient, axis=0)\n",
    "layers[2][0] -= lr * l3_w_gradient\n",
    "layers[2][1] -= lr * l3_b_gradient\n",
    "\n",
    "# form layer 3 to 2\n",
    "l2_gradient = l3_gradient @ layers[2][0].T * np.heaviside(l2_output, 0)\n",
    "l2_w_gradient = l1_output.T @ l2_gradient\n",
    "l2_b_gradient = np.mean(l2_gradient, axis=0)\n",
    "layers[1][0] -= lr * l2_w_gradient\n",
    "layers[1][1] -= lr * l2_b_gradient\n",
    "\n",
    "# from 2 to 1\n",
    "l1_gradient = l2_gradient @ layers[1][0].T * np.heaviside(l1_output, 0)\n",
    "l1_w_gradient = inputs.T @ l1_gradient\n",
    "l1_b_gradient = np.mean(l1_gradient, axis=0)\n",
    "layers[0][0] -= lr * l1_w_gradient\n",
    "layers[0][1] -= lr * l1_b_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genrating random inputs for temperatures\n",
    "def inputs_targets_genrator(n_instances: int = 10, n_features: int = 1):\n",
    "    inputs = np.random.rand(n_instances, n_features)\n",
    "    valid = np.random.rand(n_instances, n_features)\n",
    "    targets = np.random.rand(n_instances, 1)\n",
    "    valid_y = np.random.rand(n_instances, 1)\n",
    "    return inputs, targets, valid, valid_y\n",
    "\n",
    "\n",
    "# instantiating random weights and biases\n",
    "def weights_biases(nn):\n",
    "    # store the weights\n",
    "    layers = []\n",
    "    for i in range(1, len(nn)):\n",
    "        layers.append([np.random.rand(nn[i - 1], nn[i]) / 5 - 0.1, np.ones((1, nn[i]))])\n",
    "    return layers\n",
    "\n",
    "\n",
    "def forwardpass(layers, batch):\n",
    "    hidden_outputs = [batch.copy()]\n",
    "    for i in range(len(layers)):\n",
    "        batch = batch @ layers[i][0] + layers[i][1]\n",
    "        if i < len(layers) - 1:\n",
    "            batch = np.maximum(batch, 0)\n",
    "        hidden_outputs.append(batch.copy())\n",
    "    return batch, hidden_outputs\n",
    "\n",
    "\n",
    "def backpropagation(layers, hidden_outputs, grad, lr):\n",
    "    for i in range(len(layers) - 1, -1, -1):\n",
    "        if i != len(layers) - 1:\n",
    "            grad = grad * np.heaviside(hidden_outputs[i + 1], 0)\n",
    "\n",
    "        w_grad = hidden_outputs[i].T @ grad\n",
    "        b_grad = np.mean(grad, axis=0)\n",
    "\n",
    "        layers[i][0] -= lr * w_grad\n",
    "        layers[i][1] -= lr * b_grad\n",
    "        # next gradient\n",
    "        grad = grad @ layers[i][0].T\n",
    "    return layers\n",
    "\n",
    "\n",
    "def mse(actual, predicted):\n",
    "    return np.mean((actual - predicted) ** 2)\n",
    "\n",
    "\n",
    "# Correct MSE gradient function\n",
    "def mse_grad(actual, predicted):\n",
    "    n = actual.shape[0]  # Number of samples\n",
    "    return (2 / n) * (predicted - actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE: 0.004553151252362754, Valid MSE: 0.08437760165362403\n",
      "Epoch 2: Train MSE: 0.0033711728751467554, Valid MSE: 0.08435788124469525\n",
      "Epoch 3: Train MSE: 0.0033711603768920603, Valid MSE: 0.08435787803641276\n",
      "Epoch 4: Train MSE: 0.003371160529297386, Valid MSE: 0.08435789405981796\n",
      "Epoch 5: Train MSE: 0.003371160692477566, Valid MSE: 0.08435791010600138\n",
      "Epoch 6: Train MSE: 0.0033711608557006026, Valid MSE: 0.0843579261555825\n",
      "Epoch 7: Train MSE: 0.0033711610189556753, Valid MSE: 0.08435794220854209\n",
      "Epoch 8: Train MSE: 0.0033711611822427752, Valid MSE: 0.08435795826488053\n",
      "Epoch 9: Train MSE: 0.003371161345561909, Valid MSE: 0.0843579743245982\n",
      "Epoch 10: Train MSE: 0.00337116150891308, Valid MSE: 0.08435799038769548\n",
      "Epoch 11: Train MSE: 0.0033711616722962934, Valid MSE: 0.08435800645417273\n",
      "Epoch 12: Train MSE: 0.003371161835711553, Valid MSE: 0.08435802252403034\n",
      "Epoch 13: Train MSE: 0.003371161999158864, Valid MSE: 0.08435803859726869\n",
      "Epoch 14: Train MSE: 0.0033711621626382293, Valid MSE: 0.08435805467388816\n",
      "Epoch 15: Train MSE: 0.003371162326149654, Valid MSE: 0.0843580707538891\n",
      "Epoch 16: Train MSE: 0.003371162489693144, Valid MSE: 0.0843580868372719\n",
      "Epoch 17: Train MSE: 0.003371162653268702, Valid MSE: 0.08435810292403695\n",
      "Epoch 18: Train MSE: 0.0033711628168763335, Valid MSE: 0.08435811901418463\n",
      "Epoch 19: Train MSE: 0.0033711629805160425, Valid MSE: 0.08435813510771528\n",
      "Epoch 20: Train MSE: 0.0033711631441878335, Valid MSE: 0.08435815120462933\n",
      "Epoch 21: Train MSE: 0.00337116330789171, Valid MSE: 0.08435816730492712\n",
      "Epoch 22: Train MSE: 0.0033711634716276783, Valid MSE: 0.08435818340860901\n",
      "Epoch 23: Train MSE: 0.0033711636353957425, Valid MSE: 0.08435819951567541\n",
      "Epoch 24: Train MSE: 0.003371163799195905, Valid MSE: 0.08435821562612668\n",
      "Epoch 25: Train MSE: 0.0033711639630281728, Valid MSE: 0.08435823173996324\n",
      "Epoch 26: Train MSE: 0.0033711641268925497, Valid MSE: 0.08435824785718542\n",
      "Epoch 27: Train MSE: 0.0033711642907890394, Valid MSE: 0.0843582639777936\n",
      "Epoch 28: Train MSE: 0.0033711644547176466, Valid MSE: 0.08435828010178818\n",
      "Epoch 29: Train MSE: 0.0033711646186783753, Valid MSE: 0.08435829622916952\n",
      "Epoch 30: Train MSE: 0.0033711647826712315, Valid MSE: 0.08435831235993799\n",
      "Epoch 31: Train MSE: 0.0033711649466962187, Valid MSE: 0.08435832849409397\n",
      "Epoch 32: Train MSE: 0.0033711651107533416, Valid MSE: 0.08435834463163785\n",
      "Epoch 33: Train MSE: 0.0033711652748426046, Valid MSE: 0.08435836077257002\n",
      "Epoch 34: Train MSE: 0.003371165438964012, Valid MSE: 0.08435837691689083\n",
      "Epoch 35: Train MSE: 0.0033711656031175682, Valid MSE: 0.08435839306460066\n",
      "Epoch 36: Train MSE: 0.0033711657673032784, Valid MSE: 0.08435840921569988\n",
      "Epoch 37: Train MSE: 0.003371165931521146, Valid MSE: 0.0843584253701889\n",
      "Epoch 38: Train MSE: 0.0033711660957711762, Valid MSE: 0.08435844152806805\n",
      "Epoch 39: Train MSE: 0.003371166260053374, Valid MSE: 0.08435845768933779\n",
      "Epoch 40: Train MSE: 0.003371166424367743, Valid MSE: 0.08435847385399842\n",
      "Epoch 41: Train MSE: 0.0033711665887142875, Valid MSE: 0.08435849002205031\n",
      "Epoch 42: Train MSE: 0.0033711667530930125, Valid MSE: 0.08435850619349392\n",
      "Epoch 43: Train MSE: 0.0033711669175039228, Valid MSE: 0.08435852236832952\n",
      "Epoch 44: Train MSE: 0.0033711670819470225, Valid MSE: 0.08435853854655759\n",
      "Epoch 45: Train MSE: 0.0033711672464223157, Valid MSE: 0.0843585547281784\n",
      "Epoch 46: Train MSE: 0.003371167410929807, Valid MSE: 0.08435857091319245\n",
      "Epoch 47: Train MSE: 0.003371167575469502, Valid MSE: 0.08435858710160002\n",
      "Epoch 48: Train MSE: 0.0033711677400414045, Valid MSE: 0.08435860329340153\n",
      "Epoch 49: Train MSE: 0.0033711679046455182, Valid MSE: 0.08435861948859734\n",
      "Epoch 50: Train MSE: 0.003371168069281849, Valid MSE: 0.08435863568718788\n",
      "Epoch 51: Train MSE: 0.0033711682339504, Valid MSE: 0.08435865188917344\n",
      "Epoch 52: Train MSE: 0.0033711683986511775, Valid MSE: 0.08435866809455445\n",
      "Epoch 53: Train MSE: 0.003371168563384184, Valid MSE: 0.08435868430333131\n",
      "Epoch 54: Train MSE: 0.003371168728149425, Valid MSE: 0.0843587005155043\n",
      "Epoch 55: Train MSE: 0.003371168892946905, Valid MSE: 0.08435871673107392\n",
      "Epoch 56: Train MSE: 0.0033711690577766288, Valid MSE: 0.08435873295004051\n",
      "Epoch 57: Train MSE: 0.003371169222638601, Valid MSE: 0.0843587491724044\n",
      "Epoch 58: Train MSE: 0.003371169387532825, Valid MSE: 0.08435876539816599\n",
      "Epoch 59: Train MSE: 0.003371169552459306, Valid MSE: 0.08435878162732569\n",
      "Epoch 60: Train MSE: 0.0033711697174180493, Valid MSE: 0.08435879785988382\n",
      "Epoch 61: Train MSE: 0.003371169882409058, Valid MSE: 0.08435881409584083\n",
      "Epoch 62: Train MSE: 0.0033711700474323373, Valid MSE: 0.08435883033519707\n",
      "Epoch 63: Train MSE: 0.0033711702124878925, Valid MSE: 0.08435884657795288\n",
      "Epoch 64: Train MSE: 0.0033711703775757265, Valid MSE: 0.08435886282410868\n",
      "Epoch 65: Train MSE: 0.0033711705426958454, Valid MSE: 0.08435887907366482\n",
      "Epoch 66: Train MSE: 0.0033711707078482524, Valid MSE: 0.08435889532662172\n",
      "Epoch 67: Train MSE: 0.0033711708730329534, Valid MSE: 0.08435891158297971\n",
      "Epoch 68: Train MSE: 0.003371171038249951, Valid MSE: 0.0843589278427392\n",
      "Epoch 69: Train MSE: 0.0033711712034992522, Valid MSE: 0.08435894410590054\n",
      "Epoch 70: Train MSE: 0.0033711713687808596, Valid MSE: 0.08435896037246414\n",
      "Epoch 71: Train MSE: 0.0033711715340947784, Valid MSE: 0.08435897664243037\n",
      "Epoch 72: Train MSE: 0.003371171699441013, Valid MSE: 0.08435899291579961\n",
      "Epoch 73: Train MSE: 0.003371171864819569, Valid MSE: 0.08435900919257219\n",
      "Epoch 74: Train MSE: 0.003371172030230449, Valid MSE: 0.08435902547274854\n",
      "Epoch 75: Train MSE: 0.003371172195673659, Valid MSE: 0.08435904175632906\n",
      "Epoch 76: Train MSE: 0.003371172361149203, Valid MSE: 0.08435905804331409\n",
      "Epoch 77: Train MSE: 0.003371172526657086, Valid MSE: 0.08435907433370399\n",
      "Epoch 78: Train MSE: 0.0033711726921973125, Valid MSE: 0.08435909062749915\n",
      "Epoch 79: Train MSE: 0.0033711728577698863, Valid MSE: 0.0843591069247\n",
      "Epoch 80: Train MSE: 0.0033711730233748124, Valid MSE: 0.08435912322530686\n",
      "Epoch 81: Train MSE: 0.0033711731890120953, Valid MSE: 0.08435913952932013\n",
      "Epoch 82: Train MSE: 0.0033711733546817396, Valid MSE: 0.08435915583674021\n",
      "Epoch 83: Train MSE: 0.003371173520383751, Valid MSE: 0.08435917214756741\n",
      "Epoch 84: Train MSE: 0.003371173686118132, Valid MSE: 0.08435918846180217\n",
      "Epoch 85: Train MSE: 0.003371173851884888, Valid MSE: 0.08435920477944486\n",
      "Epoch 86: Train MSE: 0.0033711740176840237, Valid MSE: 0.08435922110049585\n",
      "Epoch 87: Train MSE: 0.003371174183515544, Valid MSE: 0.08435923742495553\n",
      "Epoch 88: Train MSE: 0.0033711743493794535, Valid MSE: 0.08435925375282424\n",
      "Epoch 89: Train MSE: 0.0033711745152757563, Valid MSE: 0.0843592700841024\n",
      "Epoch 90: Train MSE: 0.0033711746812044568, Valid MSE: 0.08435928641879036\n",
      "Epoch 91: Train MSE: 0.0033711748471655597, Valid MSE: 0.08435930275688856\n",
      "Epoch 92: Train MSE: 0.00337117501315907, Valid MSE: 0.0843593190983973\n",
      "Epoch 93: Train MSE: 0.0033711751791849916, Valid MSE: 0.084359335443317\n",
      "Epoch 94: Train MSE: 0.00337117534524333, Valid MSE: 0.08435935179164804\n",
      "Epoch 95: Train MSE: 0.003371175511334089, Valid MSE: 0.08435936814339078\n",
      "Epoch 96: Train MSE: 0.0033711756774572736, Valid MSE: 0.08435938449854559\n",
      "Epoch 97: Train MSE: 0.003371175843612888, Valid MSE: 0.08435940085711291\n",
      "Epoch 98: Train MSE: 0.003371176009800937, Valid MSE: 0.08435941721909304\n",
      "Epoch 99: Train MSE: 0.0033711761760214253, Valid MSE: 0.0843594335844864\n",
      "Epoch 100: Train MSE: 0.0033711763422743573, Valid MSE: 0.08435944995329338\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 10\n",
    "n_instances = 10000\n",
    "n_features = 2\n",
    "layer_config = [n_features, 2, 4, 3, 1]\n",
    "\n",
    "\n",
    "layers = weights_biases(layer_config)\n",
    "\n",
    "inputs, targets, valid, valid_y = inputs_targets_genrator(\n",
    "    n_instances=n_instances, n_features=n_features\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    for i in range(0, inputs.shape[0], batch_size):\n",
    "        train_x = inputs[i : (i + batch_size)]\n",
    "        train_y = targets[i : (i + batch_size)]\n",
    "\n",
    "        prediction, hidden_ouputs = forwardpass(layers, train_x)\n",
    "        loss = mse_grad(train_y, prediction)\n",
    "        epoch_loss.append(np.mean(loss**2))\n",
    "\n",
    "        layers = backpropagation(layers, hidden_ouputs, loss, lr)\n",
    "\n",
    "    valid_pred, _ = forwardpass(layers, valid)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}: Train MSE: {np.mean(epoch_loss)}, Valid MSE: {mse(valid_y, valid_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_creator(n_convos):\n",
    "    mr = [\"R:\"]\n",
    "    convos = []\n",
    "    for n in range(n_convos):\n",
    "        x = [\"M\"] + mr * np.random.randint(1, 5)\n",
    "        convos.extend(x)\n",
    "    return convos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = conversation_creator(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_frame = []\n",
    "conversation = []\n",
    "r_counter = 0\n",
    "for curr in data:\n",
    "    if conversation and curr.startswith(\"M\"):\n",
    "        main_frame.append(\"\\n\".join(conversation))\n",
    "        conversation = []\n",
    "        r_counter = 0\n",
    "    if curr.startswith(\"R\"):\n",
    "        r_counter += 1\n",
    "    conversation.append(curr + str(r_counter))\n",
    "if conversation:\n",
    "    main_frame.append(\"\\n\".join(conversation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4dd'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"dd\"\n",
    "\"4\" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M0\\nR:1\\nR:2\\nR:3\\nR:4',\n",
       " 'M0\\nR:1\\nR:2\\nR:3\\nR:4',\n",
       " 'M0\\nR:1\\nR:2\\nR:3',\n",
       " 'M0\\nR:1',\n",
       " 'M0\\nR:1\\nR:2\\nR:3']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
