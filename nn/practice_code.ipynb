{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tsensor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nn = [1, 3, 4, 2, 1]\n",
    "inputs = np.random.randint(10, 100, 10).reshape(10, 1)\n",
    "tagets = [n + np.random.randint(-5, 5) for n in inputs]\n",
    "lr = 1e-5\n",
    "\n",
    "# instantiation ransom weights and biases\n",
    "np.random.seed(42)\n",
    "layers = []\n",
    "for i in range(1, len(nn)):\n",
    "    layers.append([np.random.rand(nn[i - 1], nn[i]) / 5 - 0.1, np.ones((1, nn[i]))])\n",
    "\n",
    "# forward pass\n",
    "l1_output = np.maximum(0, inputs @ layers[0][0] + layers[0][1])  # hidden layer 1 output\n",
    "l2_output = np.maximum(\n",
    "    0, l1_output @ layers[1][0] + layers[1][1]\n",
    ")  # hidden layer 2 output\n",
    "l3_output = np.maximum(\n",
    "    0, l2_output @ layers[2][0] + layers[2][1]\n",
    ")  # hidden layer 3 output\n",
    "output = l3_output @ layers[3][0] + layers[3][1]  # output layers without relu\n",
    "\n",
    "# back propagation and weight and bias updates\n",
    "# from output to layer 4\n",
    "output_gradient = output\n",
    "l4_w_gradient = l3_output.T @ output_gradient\n",
    "l4_b_gradient = np.mean(output_gradient, axis=0)\n",
    "layers[3][0] -= lr * l4_w_gradient\n",
    "layers[3][1] -= lr * l4_b_gradient\n",
    "\n",
    "# from layer4 to layer3\n",
    "l3_gradient = output_gradient @ layers[3][0].T * np.heaviside(l3_output, 0)\n",
    "l3_w_gradient = l2_output.T @ l3_gradient\n",
    "l3_b_gradient = np.mean(l3_gradient, axis=0)\n",
    "layers[2][0] -= lr * l3_w_gradient\n",
    "layers[2][1] -= lr * l3_b_gradient\n",
    "\n",
    "# form layer 3 to 2\n",
    "l2_gradient = l3_gradient @ layers[2][0].T * np.heaviside(l2_output, 0)\n",
    "l2_w_gradient = l1_output.T @ l2_gradient\n",
    "l2_b_gradient = np.mean(l2_gradient, axis=0)\n",
    "layers[1][0] -= lr * l2_w_gradient\n",
    "layers[1][1] -= lr * l2_b_gradient\n",
    "\n",
    "# from 2 to 1\n",
    "l1_gradient = l2_gradient @ layers[1][0].T * np.heaviside(l1_output, 0)\n",
    "l1_w_gradient = inputs.T @ l1_gradient\n",
    "l1_b_gradient = np.mean(l1_gradient, axis=0)\n",
    "layers[0][0] -= lr * l1_w_gradient\n",
    "layers[0][1] -= lr * l1_b_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genrating random inputs for temperatures\n",
    "def inputs_targets_genrator(n_instances: int = 10, n_features: int = 1):\n",
    "    inputs = np.random.rand(n_instances, n_features)\n",
    "    valid = np.random.rand(n_instances, n_features)\n",
    "    targets = np.random.rand(n_instances, 1)\n",
    "    valid_y = np.random.rand(n_instances, 1)\n",
    "    return inputs, targets, valid, valid_y\n",
    "\n",
    "\n",
    "# instantiating random weights and biases\n",
    "def weights_biases(nn):\n",
    "    # store the weights\n",
    "    layers = []\n",
    "    for i in range(1, len(nn)):\n",
    "        layers.append([np.random.rand(nn[i - 1], nn[i]) / 5 - 0.1, np.ones((1, nn[i]))])\n",
    "    return layers\n",
    "\n",
    "\n",
    "def forwardpass(layers, batch):\n",
    "    hidden_outputs = [batch.copy()]\n",
    "    for i in range(len(layers)):\n",
    "        batch = batch @ layers[i][0] + layers[i][1]\n",
    "        if i < len(layers) - 1:\n",
    "            np.maximum(batch, 0)\n",
    "        hidden_outputs.append(batch.copy())\n",
    "    return batch, hidden_outputs\n",
    "\n",
    "\n",
    "def backpropagation(layers, hidden_outputs, grad, lr):\n",
    "    for i in range(len(layers) - 1, -1, -1):\n",
    "        if i != len(layers) - 1:\n",
    "            grad = grad * np.heaviside(hidden_outputs[i + 1], 0)\n",
    "\n",
    "        w_grad = hidden_outputs[i].T @ grad\n",
    "        b_grad = np.mean(grad, axis=0)\n",
    "\n",
    "        layers[i][0] -= lr * w_grad\n",
    "        layers[i][1] -= lr * b_grad\n",
    "        # next gradient\n",
    "        grad = grad @ layers[i][0].T\n",
    "    return layers\n",
    "\n",
    "\n",
    "def mse(actual, predicted):\n",
    "    return np.mean((actual - predicted) ** 2)\n",
    "\n",
    "\n",
    "# Correct MSE gradient function\n",
    "def mse_grad(actual, predicted):\n",
    "    n = actual.shape[0]  # Number of samples\n",
    "    return (2 / n) * (predicted - actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train MSE: 0.0252690926926085, Valid MSE: 0.10067988309449297\n",
      "Epoch 2: Train MSE: 0.013362381200240882, Valid MSE: 0.08517100151940045\n",
      "Epoch 3: Train MSE: 0.012796849374726754, Valid MSE: 0.0839247116741727\n",
      "Epoch 4: Train MSE: 0.012778590802019672, Valid MSE: 0.08375733016766954\n",
      "Epoch 5: Train MSE: 0.01277903008372786, Valid MSE: 0.0837271422042113\n",
      "Epoch 6: Train MSE: 0.01277928636877364, Valid MSE: 0.08372122133464316\n",
      "Epoch 7: Train MSE: 0.012779345129850789, Valid MSE: 0.08372003767269251\n",
      "Epoch 8: Train MSE: 0.012779357764485228, Valid MSE: 0.08371979913633783\n",
      "Epoch 9: Train MSE: 0.012779360882951323, Valid MSE: 0.08371974999635219\n",
      "Epoch 10: Train MSE: 0.012779362081755723, Valid MSE: 0.08371973884168804\n",
      "Epoch 11: Train MSE: 0.01277936289506358, Valid MSE: 0.08371973530622083\n",
      "Epoch 12: Train MSE: 0.012779363631054643, Valid MSE: 0.08371973329899123\n",
      "Epoch 13: Train MSE: 0.012779364351565809, Valid MSE: 0.08371973159828107\n",
      "Epoch 14: Train MSE: 0.012779365069001307, Valid MSE: 0.0837197299590542\n",
      "Epoch 15: Train MSE: 0.012779365785849086, Valid MSE: 0.08371972833216779\n",
      "Epoch 16: Train MSE: 0.01277936650260813, Valid MSE: 0.08371972670776671\n",
      "Epoch 17: Train MSE: 0.012779367219378508, Valid MSE: 0.08371972508387483\n",
      "Epoch 18: Train MSE: 0.012779367936180291, Valid MSE: 0.08371972346009585\n",
      "Epoch 19: Train MSE: 0.012779368653017494, Valid MSE: 0.0837197218363504\n",
      "Epoch 20: Train MSE: 0.01277936936989093, Valid MSE: 0.08371972021262247\n",
      "Epoch 21: Train MSE: 0.012779370086800761, Valid MSE: 0.08371971858890895\n",
      "Epoch 22: Train MSE: 0.01277937080374702, Valid MSE: 0.08371971696520913\n",
      "Epoch 23: Train MSE: 0.012779371520729716, Valid MSE: 0.08371971534152292\n",
      "Epoch 24: Train MSE: 0.012779372237748854, Valid MSE: 0.08371971371785034\n",
      "Epoch 25: Train MSE: 0.012779372954804427, Valid MSE: 0.08371971209419135\n",
      "Epoch 26: Train MSE: 0.01277937367189644, Valid MSE: 0.08371971047054595\n",
      "Epoch 27: Train MSE: 0.012779374389024895, Valid MSE: 0.08371970884691415\n",
      "Epoch 28: Train MSE: 0.012779375106189794, Valid MSE: 0.08371970722329597\n",
      "Epoch 29: Train MSE: 0.012779375823391136, Valid MSE: 0.08371970559969143\n",
      "Epoch 30: Train MSE: 0.012779376540628917, Valid MSE: 0.08371970397610047\n",
      "Epoch 31: Train MSE: 0.012779377257903147, Valid MSE: 0.08371970235252323\n",
      "Epoch 32: Train MSE: 0.012779377975213821, Valid MSE: 0.08371970072895951\n",
      "Epoch 33: Train MSE: 0.012779378692560944, Valid MSE: 0.0837196991054095\n",
      "Epoch 34: Train MSE: 0.01277937940994451, Valid MSE: 0.0837196974818731\n",
      "Epoch 35: Train MSE: 0.012779380127364529, Valid MSE: 0.0837196958583504\n",
      "Epoch 36: Train MSE: 0.012779380844820993, Valid MSE: 0.08371969423484134\n",
      "Epoch 37: Train MSE: 0.012779381562313907, Valid MSE: 0.08371969261134593\n",
      "Epoch 38: Train MSE: 0.012779382279843276, Valid MSE: 0.0837196909878642\n",
      "Epoch 39: Train MSE: 0.012779382997409097, Valid MSE: 0.08371968936439617\n",
      "Epoch 40: Train MSE: 0.012779383715011368, Valid MSE: 0.08371968774094181\n",
      "Epoch 41: Train MSE: 0.012779384432650092, Valid MSE: 0.08371968611750111\n",
      "Epoch 42: Train MSE: 0.01277938515032527, Valid MSE: 0.08371968449407412\n",
      "Epoch 43: Train MSE: 0.01277938586803691, Valid MSE: 0.08371968287066082\n",
      "Epoch 44: Train MSE: 0.012779386585785002, Valid MSE: 0.08371968124726124\n",
      "Epoch 45: Train MSE: 0.012779387303569548, Valid MSE: 0.08371967962387537\n",
      "Epoch 46: Train MSE: 0.012779388021390553, Valid MSE: 0.08371967800050323\n",
      "Epoch 47: Train MSE: 0.012779388739248021, Valid MSE: 0.0837196763771448\n",
      "Epoch 48: Train MSE: 0.012779389457141948, Valid MSE: 0.08371967475380007\n",
      "Epoch 49: Train MSE: 0.012779390175072333, Valid MSE: 0.08371967313046909\n",
      "Epoch 50: Train MSE: 0.012779390893039184, Valid MSE: 0.08371967150715186\n",
      "Epoch 51: Train MSE: 0.012779391611042494, Valid MSE: 0.08371966988384838\n",
      "Epoch 52: Train MSE: 0.012779392329082269, Valid MSE: 0.08371966826055866\n",
      "Epoch 53: Train MSE: 0.01277939304715851, Valid MSE: 0.08371966663728266\n",
      "Epoch 54: Train MSE: 0.012779393765271214, Valid MSE: 0.08371966501402042\n",
      "Epoch 55: Train MSE: 0.012779394483420385, Valid MSE: 0.08371966339077201\n",
      "Epoch 56: Train MSE: 0.01277939520160602, Valid MSE: 0.0837196617675373\n",
      "Epoch 57: Train MSE: 0.01277939591982813, Valid MSE: 0.08371966014431641\n",
      "Epoch 58: Train MSE: 0.012779396638086702, Valid MSE: 0.08371965852110931\n",
      "Epoch 59: Train MSE: 0.012779397356381748, Valid MSE: 0.08371965689791597\n",
      "Epoch 60: Train MSE: 0.012779398074713259, Valid MSE: 0.08371965527473646\n",
      "Epoch 61: Train MSE: 0.012779398793081249, Valid MSE: 0.08371965365157073\n",
      "Epoch 62: Train MSE: 0.012779399511485705, Valid MSE: 0.08371965202841883\n",
      "Epoch 63: Train MSE: 0.012779400229926638, Valid MSE: 0.08371965040528075\n",
      "Epoch 64: Train MSE: 0.012779400948404044, Valid MSE: 0.08371964878215646\n",
      "Epoch 65: Train MSE: 0.012779401666917926, Valid MSE: 0.08371964715904599\n",
      "Epoch 66: Train MSE: 0.012779402385468286, Valid MSE: 0.08371964553594938\n",
      "Epoch 67: Train MSE: 0.01277940310405512, Valid MSE: 0.08371964391286658\n",
      "Epoch 68: Train MSE: 0.012779403822678432, Valid MSE: 0.08371964228979765\n",
      "Epoch 69: Train MSE: 0.012779404541338222, Valid MSE: 0.08371964066674258\n",
      "Epoch 70: Train MSE: 0.012779405260034493, Valid MSE: 0.08371963904370133\n",
      "Epoch 71: Train MSE: 0.012779405978767247, Valid MSE: 0.08371963742067397\n",
      "Epoch 72: Train MSE: 0.012779406697536477, Valid MSE: 0.08371963579766045\n",
      "Epoch 73: Train MSE: 0.012779407416342193, Valid MSE: 0.08371963417466083\n",
      "Epoch 74: Train MSE: 0.012779408135184389, Valid MSE: 0.08371963255167506\n",
      "Epoch 75: Train MSE: 0.012779408854063075, Valid MSE: 0.0837196309287032\n",
      "Epoch 76: Train MSE: 0.01277940957297824, Valid MSE: 0.08371962930574521\n",
      "Epoch 77: Train MSE: 0.012779410291929893, Valid MSE: 0.08371962768280113\n",
      "Epoch 78: Train MSE: 0.012779411010918031, Valid MSE: 0.0837196260598709\n",
      "Epoch 79: Train MSE: 0.01277941172994266, Valid MSE: 0.08371962443695463\n",
      "Epoch 80: Train MSE: 0.012779412449003776, Valid MSE: 0.08371962281405226\n",
      "Epoch 81: Train MSE: 0.012779413168101383, Valid MSE: 0.08371962119116384\n",
      "Epoch 82: Train MSE: 0.012779413887235478, Valid MSE: 0.08371961956828929\n",
      "Epoch 83: Train MSE: 0.012779414606406064, Valid MSE: 0.08371961794542868\n",
      "Epoch 84: Train MSE: 0.012779415325613143, Valid MSE: 0.08371961632258203\n",
      "Epoch 85: Train MSE: 0.012779416044856716, Valid MSE: 0.08371961469974933\n",
      "Epoch 86: Train MSE: 0.012779416764136782, Valid MSE: 0.08371961307693056\n",
      "Epoch 87: Train MSE: 0.012779417483453343, Valid MSE: 0.08371961145412572\n",
      "Epoch 88: Train MSE: 0.0127794182028064, Valid MSE: 0.08371960983133485\n",
      "Epoch 89: Train MSE: 0.012779418922195952, Valid MSE: 0.08371960820855796\n",
      "Epoch 90: Train MSE: 0.012779419641622002, Valid MSE: 0.08371960658579503\n",
      "Epoch 91: Train MSE: 0.012779420361084553, Valid MSE: 0.08371960496304609\n",
      "Epoch 92: Train MSE: 0.012779421080583601, Valid MSE: 0.0837196033403111\n",
      "Epoch 93: Train MSE: 0.012779421800119149, Valid MSE: 0.0837196017175901\n",
      "Epoch 94: Train MSE: 0.012779422519691197, Valid MSE: 0.08371960009488313\n",
      "Epoch 95: Train MSE: 0.012779423239299752, Valid MSE: 0.08371959847219014\n",
      "Epoch 96: Train MSE: 0.012779423958944807, Valid MSE: 0.08371959684951118\n",
      "Epoch 97: Train MSE: 0.012779424678626366, Valid MSE: 0.08371959522684623\n",
      "Epoch 98: Train MSE: 0.012779425398344429, Valid MSE: 0.08371959360419527\n",
      "Epoch 99: Train MSE: 0.012779426118098996, Valid MSE: 0.08371959198155833\n",
      "Epoch 100: Train MSE: 0.012779426837890073, Valid MSE: 0.08371959035893545\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "epochs = 100\n",
    "batch_size = 5\n",
    "n_instances = 1000\n",
    "n_features = 2\n",
    "layer_config = [n_features, 2, 4, 3, 1]\n",
    "\n",
    "\n",
    "layers = weights_biases(layer_config)\n",
    "\n",
    "inputs, targets, valid, valid_y = inputs_targets_genrator(\n",
    "    n_instances=n_instances, n_features=n_features\n",
    ")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    for i in range(0, inputs.shape[0], batch_size):\n",
    "        train_x = inputs[i : (i + batch_size)]\n",
    "        train_y = targets[i : (i + batch_size)]\n",
    "\n",
    "        prediction, hidden_ouputs = forwardpass(layers, train_x)\n",
    "        loss = mse_grad(train_y, prediction)\n",
    "        epoch_loss.append(np.mean(loss**2))\n",
    "\n",
    "        layers = backpropagation(layers, hidden_ouputs, loss, lr)\n",
    "\n",
    "    valid_pred, _ = forwardpass(layers, valid)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}: Train MSE: {np.mean(epoch_loss)}, Valid MSE: {mse(valid_y, valid_pred)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
